# papernotes

#### 2018-07
- TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing [[arXiv](https://arxiv.org/abs/1807.10875)]
- Glow: Generative Flow with Invertible 1x1 Convolutions [[arXiv](https://arxiv.org/abs/1807.03039)]
- Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization [[arXiv](https://arxiv.org/abs/1807.00442)] [[Code](https://github.com/cxxgtxy/POP3D)]
- Representation Learning with Contrastive Predictive Coding [[arXiv](https://arxiv.org/abs/1807.03748)]
- Latent Alignment and Variational Attention [[arXiv](https://arxiv.org/abs/1807.03756)]
- Encoding Spatial Relations from Natural Language [[arXiv](https://arxiv.org/abs/1807.01670)]
- The GAN Landscape: Losses, Architectures, Regularization, and Normalization [[arXiv](https://arxiv.org/abs/1807.04720)] [[Code](https://github.com/google/compare_gan)]
- Conditional Neural Processes [[arXiv](https://arxiv.org/abs/1807.01613)]
- Neural Processes [[arXiv](https://arxiv.org/abs/1807.01622)]
- Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study [[arXiv](https://arxiv.org/abs/1807.01270)]

#### 2018-06
- Efficient Neural Architecture Search with Network Morphism [[arXiv](https://arxiv.org/abs/1806.10282)] [[Code](https://autokeras.com/)]
- Design Challenges and Misconceptions in Neural Sequence Labeling [[arXiv](https://arxiv.org/abs/1806.04470)] [[Code](https://github.com/jiesutd/NCRFpp)]
- Guided evolutionary strategies: escaping the curse of dimensionality in random search [[arXiv](https://arxiv.org/abs/1806.10230)]
- Theory IIIb: Generalization in Deep Networks [[arXiv](https://arxiv.org/abs/1806.11379)]
- Hierarchical Graph Representation Learning with Differentiable Pooling [[arXiv](https://arxiv.org/abs/1806.08804)]
- On the Spectral Bias of Deep Neural Networks [[arXiv](https://arxiv.org/abs/1806.08734)]
- Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering [[arXiv](https://arxiv.org/abs/1806.04330)] [[Code](https://github.com/lanwuwei/SPM_toolkit)]
- Gaussian mixture models with Wasserstein distance [[arXiv](https://arxiv.org/abs/1806.04465)]
- Adversarial Reprogramming of Neural Networks [[arXiv](https://arxiv.org/abs/1806.11146)]
- Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization [[arXiv](https://arxiv.org/abs/1806.08054)]
- An empirical study on evaluation metrics of generative adversarial networks [[arXiv](https://arxiv.org/abs/1806.07755)]
- Relational recurrent neural networks [[arXiv](https://arxiv.org/abs/1806.01822)]
- RUDDER: Return Decomposition for Delayed Rewards [[arXiv](https://arxiv.org/abs/1806.07857)] [[Code](https://github.com/ml-jku/baselines-rudder)]
- Playing Atari with Six Neurons [[arXiv](https://arxiv.org/abs/1806.01363)]
- Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks [[arXiv](https://arxiv.org/abs/1806.05393)]
- GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations [[arXiv](https://arxiv.org/abs/1806.05662)]
- Know What You Don't Know: Unanswerable Questions for SQuAD [[arXiv](https://arxiv.org/abs/1806.03822)] [[dataset](https://rajpurkar.github.io/SQuAD-explorer/)]
- Relational inductive biases, deep learning, and graph networks [[arXiv](https://arxiv.org/abs/1806.01261)]

#### ICML-18
- Delayed Impact of Fair Machine Learning [[arXiv](https://arxiv.org/abs/1803.04383)]
- Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples [[arXiv](https://arxiv.org/abs/1802.00420)] [[Code](https://github.com/anishathalye/obfuscated-gradients)]
- Delayed Impact of Fair Machine Learning [[arXiv](https://arxiv.org/abs/1803.04383)]

#### 2018-05
- Hybrid semi-Markov CRF for Neural Sequence Labeling [[arXiv](https://arxiv.org/abs/1805.03838)] [[Code](https://github.com/ZhixiuYe/HSCRF-pytorch)]
- Chinese NER Using Lattice LSTM [[arXiv](https://arxiv.org/abs/1805.02023)] [[Code](https://github.com/jiesutd/LatticeLSTM)]
- Gaussian Mixture Latent Vector Grammars [[arXiv](https://arxiv.org/abs/1805.04688)] [[Code](https://github.com/zhaoyanpeng/lveg)]
- Transformation Networks for Target-Oriented Sentiment Classification [[arXiv](https://arxiv.org/abs/1805.01086)] [[Code](https://github.com/lixin4ever/TNet)]
- Hybrid semi-Markov CRF for Neural Sequence Labeling [[arXiv](https://arxiv.org/abs/1805.03838)] [[Code](https://github.com/ZhixiuYe/HSCRF-pytorch)]
- What you can cram into a single vector: Probing sentence embeddings for linguistic properties [[arXiv](https://arxiv.org/abs/1805.01070)]
- Training Classifiers with Natural Language Explanations [[arXiv](https://arxiv.org/abs/1805.03818)] [[Code](https://github.com/HazyResearch/babble)]
- Deep Reinforcement Learning For Sequence to Sequence Models [[arXiv](https://arxiv.org/abs/1805.09461)] [[Code](https://github.com/yaserkl/RLSeq2Seq)]
- Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms [[arXiv](https://arxiv.org/abs/1805.09843)] [[Code](https://github.com/dinghanshen/SWEM)]
- Learning to Ask Good Questions: Ranking Clarification Questions using Neural Expected Value of Perfect Information [[arXiv](https://arxiv.org/abs/1805.04655)]
- Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context [[arXiv](https://arxiv.org/abs/1805.04623)]
- Small steps and giant leaps: Minimal Newton solvers for Deep Learning [[arXiv](https://arxiv.org/abs/1805.08095)] [[Code](https://github.com/jotaf98/curveball)]
- AutoAugment: Learning Augmentation Policies from Data [[arXiv](https://arxiv.org/abs/1805.09501)]
- Meta-Gradient Reinforcement Learning [[arXiv](https://arxiv.org/abs/1805.09801)]
- Born Again Neural Networks [[arXiv](https://arxiv.org/abs/1805.04770)]
- Convolutional CRFs for Semantic Segmentation [[arXiv](https://arxiv.org/abs/1805.04777)]  [[Code](https://github.com/MarvinTeichmann/ConvCRF)]
- Did the Model Understand the Question? [[arXiv](https://arxiv.org/abs/1805.05492)] [[Code](https://github.com/pramodkaushik/acl18_results)]
- From Word to Sense Embeddings: A Survey on Vector Representations of Meaning [[arXiv](https://arxiv.org/abs/1805.04032v2)]
- Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review [[arXiv](https://arxiv.org/abs/1805.00909)]

#### 2018-04
- Taskonomy: Disentangling Task Transfer Learning [[arXiv](https://arxiv.org/abs/1804.08328)] [[Code](https://github.com/StanfordVL/taskonomy)]
- Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation [[arXiv](https://arxiv.org/abs/1804.08069)] [[Code](https://github.com/snakeztc/NeuralDialog-LAED)]
- Learning Semantic Textual Similarity from Conversations [[arXiv](https://arxiv.org/abs/1804.07754)]
- When and Why are Pre-trained Word Embeddings Useful for Neural Machine Translation? [[arXiv](https://arxiv.org/abs/1804.06323v2)]
- QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension [[arXiv](https://arxiv.org/abs/1804.09541v1)] [[Code](https://github.com/hengruo/QANet-pytorch)]
- Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models [[arXiv](https://arxiv.org/abs/1804.09299)] [[Code](https://github.com/HendrikStrobelt/Seq2Seq-Vis)]
- Low Rank Structure of Learned Representations [[arXiv](https://arxiv.org/abs/1804.07090)]
- Decoupled Networks [[arXiv](https://arxiv.org/abs/1804.08071)]
- Learned Deformation Stability in Convolutional Neural Networks [[arXiv](https://arxiv.org/abs/1804.04438)]
- Phrase-Based & Neural Unsupervised Machine Translation [[arXiv](https://arxiv.org/abs/1804.07755)]
- Learning to Map Context-Dependent Sentences to Executable Formal Queries [[arXiv](https://arxiv.org/abs/1804.06868)] [[Code](https://github.com/clic-lab/atis)]
- Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations [[arXiv](https://arxiv.org/abs/1804.02485)]
- Differentiable plasticity: training plastic neural networks with backpropagation [[arXiv](https://arxiv.org/abs/1804.02464)]
- Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning [[arXiv](https://arxiv.org/abs/1804.00079v1)] [[Code](https://github.com/Maluuba/gensen)]

#### 2018-03
- Variance Networks: When Expectation Does Not Meet Your Expectations [[arXiv](https://arxiv.org/abs/1803.03764)]
- Referring Relationships [[arXiv](https://arxiv.org/abs/1803.10362)]
- Iterative Visual Reasoning Beyond Convolutions [[arXiv](https://arxiv.org/abs/1803.11189)]
- World Models [[arXiv](https://arxiv.org/abs/1803.10122)]
- Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning [[arXiv](https://arxiv.org/abs/1803.05268)]
- A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay [[arXiv](https://arxiv.org/abs/1803.09820)]
- Feudal Reinforcement Learning for Dialogue Management in Large Domains [[arXiv](https://arxiv.org/abs/1803.03232)]
- Universal Sentence Encoder [[arXiv](https://arxiv.org/abs/1803.11175v1)]
- Averaging Weights Leads to Wider Optima and Better Generalization [[arXiv](https://arxiv.org/abs/1803.05407v1)]
- On the importance of single directions for generalization [[arXiv](https://arxiv.org/abs/1803.06959)]
- Group Normalization [[arXiv](https://arxiv.org/abs/1803.08494)]
- Compositional Attention Networks for Machine Reasoning [[arXiv](https://arxiv.org/abs/1803.03067)]
- Learning Longer-term Dependencies in RNNs with Auxiliary Losses [[arXiv](https://arxiv.org/abs/1803.00144)]

#### 2018-02
- Regularized Evolution for Image Classifier Architecture Search [[arXiv](https://arxiv.org/abs/1802.01548)]
- Visual Interpretability for Deep Learning: a Survey [[arXiv](https://arxiv.org/abs/1802.00614)]
- Deep contextualized word representation [[arXiv](https://arxiv.org/abs/1802.05365v2)]
- Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs [[arXiv](https://arxiv.org/abs/1802.10026)]
- Machine Theory of Mind [[arXiv](https://arxiv.org/abs/1802.07740)] 
- Efficient Neural Architecture Search via Parameter Sharing [[arXiv](https://arxiv.org/abs/1802.03268)]
- Interpreting CNNs via Decision Trees [[arXiv](https://arxiv.org/abs/1802.00121)]
- DensePose: Dense Human Pose Estimation In The Wild [[arXiv](https://arxiv.org/abs/1802.00434)] [[dataset](http://densepose.org/)]
- DeepType: Multilingual Entity Linking by Neural Type System Evolution [[arXiv](https://arxiv.org/abs/1802.01021)] [[Code](https://github.com/openai/deeptype)]
- Recent Advances in Neural Program Synthesis [[arXiv](https://arxiv.org/abs/1802.02353)]
- IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures [[arXiv](https://arxiv.org/abs/1802.01561)] [[Code](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/dmlab30)]
- Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples [[arXiv](https://arxiv.org/abs/1802.00420)] [[Code](https://github.com/anishathalye/obfuscated-gradients)]

#### 2018-01
- Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling [[arXiv](https://arxiv.org/abs/1801.10296)]
- Quantum Computing in the NISQ era and beyond [[arXiv](https://arxiv.org/abs/1801.00862)]
- Active Neural Localization [[arXiv](https://arxiv.org/abs/1801.08214)]
- Global overview of Imitation Learning [[arXiv](https://arxiv.org/abs/1801.06503)]
- MaskGAN: Better Text Generation via Filling in the ______ [[arXiv](https://arxiv.org/abs/1801.07736)] [[Code](https://github.com/tensorflow/models/tree/master/research/maskgan)]
- Deep Learning for Sentiment Analysis : A Survey [[arXiv](https://arxiv.org/abs/1801.07883)]
- Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift [[arXiv](https://arxiv.org/abs/1801.05134)]
- DENSER: Deep Evolutionary Network Structured Representation [[arXiv](https://arxiv.org/abs/1801.01563)]
- Building a Conversational Agent Overnight with Dialogue Self-Play [[arXiv](https://arxiv.org/abs/1801.04871)]
- Unsupervised Real-to-Virtual Domain Unification for End-to-End Highway Driving [[arXiv](https://arxiv.org/abs/1801.03458)]
- SBNet: Sparse Blocks Network for Fast Inference [[arXiv](https://arxiv.org/abs/1801.02108)]
- Deep Stereo Matching with Explicit Cost Aggregation Sub-Architecture [[arXiv](https://arxiv.org/abs/1801.04065)]
- Adversarial Spheres [[arXiv](https://arxiv.org/abs/1801.02774)]
- Neural Program Synthesis with Priority Queue Training [[arXiv](https://arxiv.org/abs/1801.03526)] [[Code](https://github.com/tensorflow/models/tree/master/research/brain_coder)]
- Adversarial Generative Nets: Neural Network Attacks on State-of-the-Art Face Recognition [[arXiv](https://arxiv.org/abs/1801.00349)]
- DeepMind Control Suite [[arXiv](https://arxiv.org/abs/1801.00690)] [[dataset](https://github.com/deepmind/dm_control)]

#### 2017-12
- Noisy Natural Gradient as Variational Inference [[arXiv](https://arxiv.org/abs/1712.02390)] [[Code](https://github.com/wlwkgus/NoisyNaturalGradient)]
- Non-convex Optimization for Machine Learning [[arXiv](https://arxiv.org/abs/1712.07897)]
- Improving Generalization Performance by Switching from Adam to SGD [[arXiv](https://arxiv.org/abs/1712.07628v1)]
- Learning by Asking Questions [[arXiv](https://arxiv.org/abs/1712.01238v1)]
- A Flexible Approach to Automated RNN Architecture Generation [[arXiv](https://arxiv.org/abs/1712.07316v1)]
- Lectures on Randomized Numerical Linear Algebra [[arXiv](https://arxiv.org/abs/1712.08880)]
- Data Distillation: Towards Omni-Supervised Learning [[arXiv](https://arxiv.org/abs/1712.04440)]
- Deep Learning Scaling is Predictable, Empirically [[arXiv](https://arxiv.org/abs/1712.00409v1)]
- SGAN: An Alternative Training of Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1712.02330v1)]
- The NarrativeQA Reading Comprehension Challenge [[arXiv](https://arxiv.org/abs/1712.07040v1)] [[dataset](https://github.com/deepmind/narrativeqa)]
- Regularization and Optimization strategies in Deep Convolutional Neural Network [[arXiv](https://arxiv.org/abs/1712.04711)]
- Mathematics of Deep Learning [[arXiv](https://arxiv.org/abs/1712.04741)]
- Text Generation Based on Generative Adversarial Nets with Latent Variable [[arXiv](https://arxiv.org/abs/1712.00170v1)]
- Deliberation Networks: Sequence Generation Beyond One-Pass Decoding
- Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning [[arXiv](https://arxiv.org/abs/1712.02051)] [[Code](https://github.com/huanzhang12/ImageCaptioningAttack)]

#### ICLR-18
- Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling
- i-RevNet: Deep Invertible Networks
- Hierarchical Representations for Efficient Architecture Search [[arXiv](https://arxiv.org/abs/1711.00436)]
- Backpropagation through the Void: Optimizing control variates for black-box gradient estimation [[arXiv](https://arxiv.org/abs/1711.00123)] [[Code](https://github.com/duvenaud/relax)]
- Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection
- Wasserstein Auto-Encoders [[arXiv](https://arxiv.org/abs/1711.01558)]
- Neural Speed Reading via Skim-RNN [[arXiv](https://arxiv.org/abs/1711.02085)]
- Breaking the Softmax Bottleneck: A High-Rank RNN Language Model [[arXiv](https://arxiv.org/abs/1711.03953)] [[Code](https://github.com/zihangdai/mos)]
- Non-Autoregressive Neural Machine Translation [[arXiv](https://arxiv.org/abs/1711.02281)]
- A DIRT-T Approach to Unsupervised Domain Adaptation
- On the Information Bottleneck Theory of Deep Learning
- mixup: Beyond Empirical Risk Minimization
- Unsupervised Machine Translation Using Monolingual Corpora Only [[arXiv](https://arxiv.org/abs/1711.00043)]
- Matrix capsules with EM routing

#### 2017-11
- Hierarchical Representations for Efficient Architecture Search [[arXiv](https://arxiv.org/abs/1711.00436v2)]
- Embedding Words as Distributions with a Bayesian Skip-gram Model [[arXiv](https://arxiv.org/abs/1711.11027v1)]
- Deep Image Prior [[arXiv](https://arxiv.org/abs/1711.10925)] [[Code](https://github.com/DmitryUlyanov/deep-image-prior)]
- MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1711.06788v1)]
- Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning [[arXiv](https://arxiv.org/abs/1711.07613v1)]
- Neural Text Generation: A Practical Guide [[arXiv](https://arxiv.org/abs/1711.09534v1)]
- Memory Aware Synapses: Learning what (not) to forget [[arXiv](https://arxiv.org/abs/1711.09601)]
- Are GANs Created Equal? A Large-Scale Study [[arXiv](https://arxiv.org/abs/1711.10337)]
- Distilling a Neural Network Into a Soft Decision Tree [[arXiv](https://arxiv.org/abs/1711.09784)]
- SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability [[arXiv](https://arxiv.org/abs/1706.05806)] [[Code](https://github.com/google/svcca)]
- Non-local Neural Networks [[arXiv](https://arxiv.org/abs/1711.07971v1)]
- Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations [[arXiv](https://arxiv.org/abs/1711.05732)] [[dataset](https://github.com/jwieting)] [[Code](https://github.com/jwieting)]
- Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks [[arXiv](https://arxiv.org/abs/1711.00350)] [[dataset](https://github.com/brendenlake/SCAN)]
- Neural Discrete Representation Learning [[arXiv](https://arxiv.org/abs/1711.00937)]
- Weighted Transformer Network for Machine Translation [[arXiv](https://arxiv.org/abs/1711.02132)]

#### 2017-10
- Dynamic Routing Between Capsules [[arXiv](https://arxiv.org/abs/1710.09829)]
- Unsupervised Neural Machine Translation [[arXiv](https://arxiv.org/abs/1710.11041)]

#### 2017-09
- Empower Sequence Labeling with Task-Aware Neural Language Model [[arXiv](https://arxiv.org/abs/1709.04109)] [[Code](https://github.com/LiyuanLucasLiu/LM-LSTM-CRF)]
- Dynamic Evaluation of Neural Sequence Models [[arXiv](https://arxiv.org/abs/1709.07432)] [[Code](https://github.com/benkrause/dynamic-evaluation)]

#### NIPS-17
- Improved Training of Wasserstein GANs [[arXiv](https://arxiv.org/abs/1704.00028)] [[Code](https://github.com/igul222/improved_wgan_training)] [[Code](https://github.com/caogang/wgan-gp)]
- The Reversible Residual Network: Backpropagation Without Storing Activations [[arXiv](https://arxiv.org/abs/1707.04585)] [[Code](https://github.com/renmengye/revnet-public)] [[Code](https://github.com/tbung/pytorch-revnet)]
- Plan, Attend, Generate: Planning for Sequence-to-Sequence Models [[arXiv](https://arxiv.org/abs/1711.10462v1)]
- REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models [[arXiv](https://arxiv.org/abs/1703.07370)] [[Code](https://github.com/tensorflow/models/tree/master/research/rebar)]
- Poincar√© Embeddings for Learning Hierarchical Representations [[arXiv](https://arxiv.org/abs/1705.08039)]
- Character-Level Language Modeling with Recurrent Highway Hypernetworks [[Code](https://github.com/jsuarez5341/Recurrent-Highway-Hypernetworks-NIPS)] 
- Dilated Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1710.02224)] [[Code](https://github.com/code-terminator/DilatedRNN)]
- Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning [[arXiv](https://arxiv.org/abs/1711.01577)]
- Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations [[arXiv](https://arxiv.org/abs/1704.00648)]
- Learned in Translation: Contextualized Word Vectors [[arXiv](https://arxiv.org/abs/1708.00107)] [[Code](https://github.com/salesforce/cove)]

#### 2017-08
- Focal Loss for Dense Object Detection [[arXiv](https://arxiv.org/abs/1708.02002)]
- Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge [[arXiv](https://arxiv.org/abs/1708.02711)] [[Code](https://github.com/hengyuan-hu/bottom-up-attention-vqa)]

#### 2017-07
- Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering [[arXiv](https://arxiv.org/abs/1707.07998)] [[Code](https://github.com/hengyuan-hu/bottom-up-attention-vqa)]

#### 2017-06
- Self-Normalizing Neural Networks [[arXiv](https://arxiv.org/abs/1706.02515)]
- One Model To Learn Them All [[arXiv](https://arxiv.org/abs/1706.05137)] [[Code](https://github.com/tensorflow/tensor2tensor)]
- Attention Is All You Need [[arXiv](https://arxiv.org/abs/1706.03762)] [[Code](https://github.com/tensorflow/tensor2tensor)]
- A simple neural network module for relational reasoning [[arXiv](https://arxiv.org/abs/1706.01427)]

#### ICML-17
- Large-Scale Evolution of Image Classifiers [[arXiv](https://arxiv.org/abs/1703.01041)]
- Improved Variational Autoencoders for Text Modeling using Dilated Convolutions [[arXiv](https://arxiv.org/abs/1702.08139)]
- Conditional Image Synthesis With Auxiliary Classifier GANs [[arXiv](https://arxiv.org/abs/1610.09585)]
- Toward Controlled Generation of Text [[arXiv](https://arxiv.org/abs/1703.00955)]

#### 2017-05
- Ask the Right Questions: Active Question Reformulation with Reinforcement Learning [[arXiv](https://arxiv.org/abs/1705.07830)]
- Supervised Learning of Universal Sentence Representations from Natural Language Inference Data [[arXiv](https://arxiv.org/abs/1705.02364)] [[Code](https://github.com/facebookresearch/InferSent)] [[Code](https://github.com/facebookresearch/SentEval)]
- Learning to Ask: Neural Question Generation for Reading Comprehension [[arXiv](https://arxiv.org/abs/1705.00106)] [[Code](https://github.com/xinyadu/nqg)]
- Adversarial Ranking for Language Generation [[arXiv](https://arxiv.org/abs/1705.11001)]
- Learning Structured Text Representations [[arXiv](https://arxiv.org/abs/1705.09207)] [[Code](https://github.com/nlpyang/structured)]
- TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension [[arXiv](https://arxiv.org/abs/1705.03551)] [[dataset](http://nlp.cs.washington.edu/triviaqa/)] [[Code](https://github.com/mandarjoshi90/triviaqa)]
- ParlAI: A Dialog Research Software Platform [[arXiv](https://arxiv.org/abs/1705.06476)] [[Code](https://github.com/facebookresearch/ParlAI)]

#### 2017-04
- Stochastic Gradient Descent as Approximate Bayesian Inference [[arXiv](https://arxiv.org/abs/1704.04289)]
- Snapshot Ensembles: Train 1, get M for free [[arXiv](https://arxiv.org/abs/1704.00109)] [[Code](https://github.com/gaohuang/SnapshotEnsemble)] [[Code](https://github.com/titu1994/Snapshot-Ensembles)]
- From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood [[arXiv](https://arxiv.org/abs/1704.07926)] [[Code](https://github.com/kelvinguu/lang2program)]
- Reading Wikipedia to Answer Open-Domain Questions [[arXiv](https://arxiv.org/abs/1704.00051)]
- Learning to Skim Text [[arXiv](https://arxiv.org/abs/1704.06877)]

#### 2017-03
- Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks [[arXiv](https://arxiv.org/abs/1703.10593)] [[Code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]
- Evolution Strategies as a Scalable Alternative to Reinforcement Learning [[arXiv](https://arxiv.org/abs/1703.03864)] [[Code](https://github.com/openai/evolution-strategies-starter)] [[Code](https://github.com/atgambardella/pytorch-es)]

#### 2017-02
- Exploring loss function topology with cyclical learning rates [[arXiv](https://arxiv.org/abs/1702.04283)] [[Code](https://github.com/lnsmith54/exploring-loss)]
- A Hybrid Convolutional Variational Autoencoder for Text Generation [[arXiv](https://arxiv.org/abs/1702.02390)] [[Code](https://github.com/stas-semeniuta/textvae)]

#### 2017-01
- Wasserstein GAN [[arXiv](https://arxiv.org/abs/1701.07875)] [[Code](https://github.com/martinarjovsky/WassersteinGAN)]
- Adversarial Learning for Neural Dialogue Generation [[arXiv](https://arxiv.org/abs/1701.06547)]
- Deep Reinforcement Learning: An Overview [[arXiv](https://arxiv.org/abs/1701.07274)]
- OpenNMT: Open-Source Toolkit for Neural Machine Translation [[arXiv](https://arxiv.org/abs/1701.02810)] [[Code](https://github.com/OpenNMT/OpenNMT)] [[Code](https://github.com/OpenNMT/OpenNMT-py)]

#### ICLR-17
- Categorical Reparameterization with Gumbel-Softmax [[arXiv](https://arxiv.org/abs/1611.01144)]
- Adversarial Training Methods for Semi-Supervised Text Classification [[arXiv](https://arxiv.org/abs/1605.07725)] [[Code](https://github.com/tensorflow/models/tree/master/research/adversarial_text)]
- Structured Attention Networks [[arXiv](https://arxiv.org/abs/1702.00887)] [[Code](https://github.com/harvardnlp/struct-attn)]
- Learning End-to-End Goal-Oriented Dialog [[arXiv](https://arxiv.org/abs/1605.07683)] [[dataset](http://fb.ai/babi)]
- Understanding deep learning requires rethinking generalization [[arXiv](https://arxiv.org/abs/1611.03530)]
- An Actor-Critic Algorithm for Sequence Prediction [[arXiv](https://arxiv.org/abs/1607.07086)]
- Learning to Remember Rare Events [[arXiv](https://arxiv.org/abs/1703.03129)]
- Introspection: Accelerating Neural Network Training By Learning Weight Evolution [[arXiv](https://arxiv.org/abs/1704.04959)]

#### 2016-11
- Image-to-Image Translation with Conditional Adversarial Networks [[arXiv](https://arxiv.org/abs/1611.07004v2)] [[Code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]

#### 2016-10
- Using Fast Weights to Attend to the Recent Past [[arXiv](https://arxiv.org/abs/1610.06258)]

#### 2016-09
- HyperNetworks [[arXiv](https://arxiv.org/abs/1609.09106)]
- Language as a Latent Variable: Discrete Generative Models for Sentence Compression [[arXiv](https://arxiv.org/abs/1609.07317)]
- SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient [[arXiv](https://arxiv.org/abs/1609.05473)] [[Code](https://github.com/LantaoYu/SeqGAN)]

#### 2016-08
- SGDR: Stochastic Gradient Descent with Warm Restarts [[arXiv](https://arxiv.org/abs/1608.03983)] [[Code](https://github.com/loshchil/SGDR)]

#### 2016-06
- Convolution by Evolution: Differentiable Pattern Producing Networks [[arXiv](https://arxiv.org/abs/1606.02580)]
- Conditional Image Generation with PixelCNN Decoders [[arXiv](https://arxiv.org/abs/1606.05328)]
- InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [[arXiv](https://arxiv.org/abs/1606.03657)]

#### 2016-04
- Benchmarking Deep Reinforcement Learning for Continuous Control [[arXiv](https://arxiv.org/abs/1604.06778)] [[Code](https://github.com/rll/rllab)]

#### 2016-02
- Associative Long Short-Term Memory [[arXiv](https://arxiv.org/abs/1602.03032)]

#### 2015-11
- Neural Variational Inference for Text Processing [[arXiv](https://arxiv.org/abs/1511.06038)]
- Generating Sentences from a Continuous Space [[arXiv](https://arxiv.org/abs/1511.06349)]

#### 2015-06
- Cyclical Learning Rates for Training Neural Networks [[arXiv](https://arxiv.org/abs/1506.01186)] [[Code](https://github.com/bckenstler/CLR)]
- Skip-Thought Vectors [[arXiv](https://arxiv.org/abs/1506.06726)]

#### 2015-05
- U-Net: Convolutional Networks for Biomedical Image Segmentation [[arXiv](https://arxiv.org/abs/1505.04597)]

#### 2015-02
- Trust Region Policy Optimization [[arXiv](https://arxiv.org/abs/1502.05477)]

#### 2014-12
- Adam: A Method for Stochastic Optimization [[arXiv](https://arxiv.org/abs/1412.6980)]

#### 2014-11
- Conditional Generative Adversarial Nets [[arXiv](https://arxiv.org/abs/1411.1784)]

#### 2014-06
- Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1406.2661)]
- Semi-Supervised Learning with Deep Generative Models [[arXiv](https://arxiv.org/abs/1406.5298)] [[Code](https://github.com/dpkingma/nips14-ssl)]

#### 2013-12
- Auto-Encoding Variational Bayes [[arXiv](https://arxiv.org/abs/1312.6114)]

#### 2012-06
- Variational Bayesian Inference with Stochastic Search [[arXiv](https://arxiv.org/abs/1206.6430)]
