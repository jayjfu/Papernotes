# papernotes
#### 2017-12
- Non-convex Optimization for Machine Learning [[arXiv](https://arxiv.org/abs/1712.07897)]
- Improving Generalization Performance by Switching from Adam to SGD [[arXiv](https://arxiv.org/abs/1712.07628v1)]
- Learning by Asking Questions [[arXiv](https://arxiv.org/abs/1712.01238v1)]
- A Flexible Approach to Automated RNN Architecture Generation [[arXiv](https://arxiv.org/abs/1712.07316v1)]
- Lectures on Randomized Numerical Linear Algebra [[arXiv](https://arxiv.org/abs/1712.08880)]
- Data Distillation: Towards Omni-Supervised Learning [[arXiv](https://arxiv.org/abs/1712.04440)]
- Deep Learning Scaling is Predictable, Empirically [[arXiv](https://arxiv.org/abs/1712.00409v1)]
- SGAN: An Alternative Training of Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1712.02330v1)]
- The NarrativeQA Reading Comprehension Challenge [[arXiv](https://arxiv.org/abs/1712.07040v1)] [[dataset](https://github.com/deepmind/narrativeqa)]
- Regularization and Optimization strategies in Deep Convolutional Neural Network [[arXiv](https://arxiv.org/abs/1712.04711)]
- Mathematics of Deep Learning [[arXiv](https://arxiv.org/abs/1712.04741)]
- Text Generation Based on Generative Adversarial Nets with Latent Variable [[arXiv](https://arxiv.org/abs/1712.00170v1)]
- Deliberation Networks: Sequence Generation Beyond One-Pass Decoding
- Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning [[arXiv](https://arxiv.org/abs/1712.02051)] [[Code](https://github.com/huanzhang12/ImageCaptioningAttack)]

#### ICLR-18
- Backpropagation through the Void: Optimizing control variates for black-box gradient estimation [[arXiv](https://arxiv.org/abs/1711.00123)] [[Code](https://github.com/duvenaud/relax)]
- Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection
- Wasserstein Auto-Encoders [[arXiv](https://arxiv.org/abs/1711.01558)]
- Neural Speed Reading via Skim-RNN [[arXiv](https://arxiv.org/abs/1711.02085)]
- Breaking the Softmax Bottleneck: A High-Rank RNN Language Model [[arXiv](https://arxiv.org/abs/1711.03953)] [[Code](https://github.com/zihangdai/mos)]
- Non-Autoregressive Neural Machine Translation [[arXiv](https://arxiv.org/abs/1711.02281)]
- A DIRT-T Approach to Unsupervised Domain Adaptation
- On the Information Bottleneck Theory of Deep Learning
- mixup: Beyond Empirical Risk Minimization
- Unsupervised Machine Translation Using Monolingual Corpora Only [[arXiv](https://arxiv.org/abs/1711.00043)]
- Matrix capsules with EM routing

#### 2017-11
- Embedding Words as Distributions with a Bayesian Skip-gram Model [[arXiv](https://arxiv.org/abs/1711.11027v1)]
- Deep Image Prior [[arXiv](https://arxiv.org/abs/1711.10925)] [[Code](https://github.com/DmitryUlyanov/deep-image-prior)]
- MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1711.06788v1)]
- Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning [[arXiv](https://arxiv.org/abs/1711.07613v1)]
- Neural Text Generation: A Practical Guide [[arXiv](https://arxiv.org/abs/1711.09534v1)]
- Memory Aware Synapses: Learning what (not) to forget [[arXiv](https://arxiv.org/abs/1711.09601)]
- Are GANs Created Equal? A Large-Scale Study [[arXiv](https://arxiv.org/abs/1711.10337)]
- Distilling a Neural Network Into a Soft Decision Tree [[arXiv](https://arxiv.org/abs/1711.09784)]
- SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability [[arXiv](https://arxiv.org/abs/1706.05806)] [[Code](https://github.com/google/svcca)]
- Non-local Neural Networks [[arXiv](https://arxiv.org/abs/1711.07971v1)]
- Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations [[arXiv](https://arxiv.org/abs/1711.05732)] [[dataset](https://github.com/jwieting)] [[Code](https://github.com/jwieting)]
- Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks [[arXiv](https://arxiv.org/abs/1711.00350)] [[dataset](https://github.com/brendenlake/SCAN)]
- Neural Discrete Representation Learning [[arXiv](https://arxiv.org/abs/1711.00937)]
- Weighted Transformer Network for Machine Translation [[arXiv](https://arxiv.org/abs/1711.02132)]

#### 2017-10
- Dynamic Routing Between Capsules [[arXiv](https://arxiv.org/abs/1710.09829)]
- Unsupervised Neural Machine Translation [[arXiv](https://arxiv.org/abs/1710.11041)]

#### 2017-09
- Dynamic Evaluation of Neural Sequence Models [[arXiv](https://arxiv.org/abs/1709.07432)] [[Code](https://github.com/benkrause/dynamic-evaluation)]

#### NIPS-17
- Plan, Attend, Generate: Planning for Sequence-to-Sequence Models [[arXiv](https://arxiv.org/abs/1711.10462v1)]
- REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models [[arXiv](https://arxiv.org/abs/1703.07370)] [[Code](https://github.com/tensorflow/models/tree/master/research/rebar)]
- Poincar√© Embeddings for Learning Hierarchical Representations [[arXiv](https://arxiv.org/abs/1705.08039)]
- Character-Level Language Modeling with Recurrent Highway Hypernetworks [[Code](https://github.com/jsuarez5341/Recurrent-Highway-Hypernetworks-NIPS)] 
- Dilated Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1710.02224)] [[Code](https://github.com/code-terminator/DilatedRNN)]
- Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning [[arXiv](https://arxiv.org/abs/1711.01577)]
- Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations [[arXiv](https://arxiv.org/abs/1704.00648)]
- Learned in Translation: Contextualized Word Vectors [[arXiv](https://arxiv.org/abs/1708.00107)] [[Code](https://github.com/salesforce/cove)]

#### 2017-08
- Focal Loss for Dense Object Detection [[arXiv](https://arxiv.org/abs/1708.02002)]
- Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge [[arXiv](https://arxiv.org/abs/1708.02711)] [[Code](https://github.com/hengyuan-hu/bottom-up-attention-vqa)]

#### 2017-07
- Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering [[arXiv](https://arxiv.org/abs/1707.07998)] [[Code](https://github.com/hengyuan-hu/bottom-up-attention-vqa)]

#### 2017-06
- Self-Normalizing Neural Networks [[arXiv](https://arxiv.org/abs/1706.02515)]
- One Model To Learn Them All [[arXiv](https://arxiv.org/abs/1706.05137)] [[Code](https://github.com/tensorflow/tensor2tensor)]
- Attention Is All You Need [[arXiv](https://arxiv.org/abs/1706.03762)] [[Code](https://github.com/tensorflow/tensor2tensor)]
- A simple neural network module for relational reasoning [[arXiv](https://arxiv.org/abs/1706.01427)]

#### ICML-17
- Large-Scale Evolution of Image Classifiers [[arXiv](https://arxiv.org/abs/1703.01041)]
- Improved Variational Autoencoders for Text Modeling using Dilated Convolutions [[arXiv](https://arxiv.org/abs/1702.08139)]
- Conditional Image Synthesis With Auxiliary Classifier GANs [[arXiv](https://arxiv.org/abs/1610.09585)]
- Toward Controlled Generation of Text [[arXiv](https://arxiv.org/abs/1703.00955)]

#### 2017-05
- Supervised Learning of Universal Sentence Representations from Natural Language Inference Data [[arXiv](https://arxiv.org/abs/1705.02364)] [[Code](https://github.com/facebookresearch/InferSent)] [[Code](https://github.com/facebookresearch/SentEval)]
- Learning to Ask: Neural Question Generation for Reading Comprehension [[arXiv](https://arxiv.org/abs/1705.00106)] [[Code](https://github.com/xinyadu/nqg)]
- Adversarial Ranking for Language Generation [[arXiv](https://arxiv.org/abs/1705.11001)]
- Learning Structured Text Representations [[arXiv](https://arxiv.org/abs/1705.09207)] [[Code](https://github.com/nlpyang/structured)]
- TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension [[arXiv](https://arxiv.org/abs/1705.03551)] [[dataset](http://nlp.cs.washington.edu/triviaqa/)] [[Code](https://github.com/mandarjoshi90/triviaqa)]
- ParlAI: A Dialog Research Software Platform [[arXiv](https://arxiv.org/abs/1705.06476)] [[Code](https://github.com/facebookresearch/ParlAI)]

#### 2017-04
- From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood [[arXiv](https://arxiv.org/abs/1704.07926)] [[Code](https://github.com/kelvinguu/lang2program)]
- Reading Wikipedia to Answer Open-Domain Questions [[arXiv](https://arxiv.org/abs/1704.00051)]
- Learning to Skim Text [[arXiv](https://arxiv.org/abs/1704.06877)]

#### 2017-03
- Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks [[arXiv](https://arxiv.org/abs/1703.10593)] [[Code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]
- Evolution Strategies as a Scalable Alternative to Reinforcement Learning [[arXiv](https://arxiv.org/abs/1703.03864)] [[Code](https://github.com/openai/evolution-strategies-starter)] [[Code](https://github.com/atgambardella/pytorch-es)]

#### 2017-02
- A Hybrid Convolutional Variational Autoencoder for Text Generation [[arXiv](https://arxiv.org/abs/1702.02390)] [[Code](https://github.com/stas-semeniuta/textvae)]

#### 2017-01
- Adversarial Learning for Neural Dialogue Generation [[arXiv](https://arxiv.org/abs/1701.06547)]
- Deep Reinforcement Learning: An Overview [[arXiv](https://arxiv.org/abs/1701.07274)]
- OpenNMT: Open-Source Toolkit for Neural Machine Translation [[arXiv](https://arxiv.org/abs/1701.02810)] [[Code](https://github.com/OpenNMT/OpenNMT)] [[Code](https://github.com/OpenNMT/OpenNMT-py)]

#### ICLR-17
- Categorical Reparameterization with Gumbel-Softmax [[arXiv](https://arxiv.org/abs/1611.01144)]
- Adversarial Training Methods for Semi-Supervised Text Classification [[arXiv](https://arxiv.org/abs/1605.07725)] [[Code](https://github.com/tensorflow/models/tree/master/research/adversarial_text)]
- Structured Attention Networks [[arXiv](https://arxiv.org/abs/1702.00887)] [[Code](https://github.com/harvardnlp/struct-attn)]
- Learning End-to-End Goal-Oriented Dialog [[arXiv](https://arxiv.org/abs/1605.07683)] [[dataset](http://fb.ai/babi)]
- Understanding deep learning requires rethinking generalization [[arXiv](https://arxiv.org/abs/1611.03530)]
- An Actor-Critic Algorithm for Sequence Prediction [[arXiv](https://arxiv.org/abs/1607.07086)]
- Learning to Remember Rare Events [[arXiv](https://arxiv.org/abs/1703.03129)]
- Introspection: Accelerating Neural Network Training By Learning Weight Evolution [[arXiv](https://arxiv.org/abs/1704.04959)]

#### 2016-11
- Image-to-Image Translation with Conditional Adversarial Networks [[arXiv](https://arxiv.org/abs/1611.07004v2)] [[Code](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]

#### 2016-10
- Using Fast Weights to Attend to the Recent Past [[arXiv](https://arxiv.org/abs/1610.06258)]

#### 2016-09
- HyperNetworks [[arXiv](https://arxiv.org/abs/1609.09106)]
- Language as a Latent Variable: Discrete Generative Models for Sentence Compression [[arXiv](https://arxiv.org/abs/1609.07317)]
- SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient [[arXiv](https://arxiv.org/abs/1609.05473)] [[Code](https://github.com/LantaoYu/SeqGAN)]

#### 2016-06
- Convolution by Evolution: Differentiable Pattern Producing Networks [[arXiv](https://arxiv.org/abs/1606.02580)]
- Conditional Image Generation with PixelCNN Decoders [[arXiv](https://arxiv.org/abs/1606.05328)]
- InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [[arXiv](https://arxiv.org/abs/1606.03657)]

#### 2016-02
- Associative Long Short-Term Memory [[arXiv](https://arxiv.org/abs/1602.03032)]

#### 2015-11
- Neural Variational Inference for Text Processing [[arXiv](https://arxiv.org/abs/1511.06038)]
- Generating Sentences from a Continuous Space [[arXiv](https://arxiv.org/abs/1511.06349)]

#### 2015-06
- Skip-Thought Vectors [[arXiv](https://arxiv.org/abs/1506.06726)]

#### 2015-05
- U-Net: Convolutional Networks for Biomedical Image Segmentation [[arXiv](https://arxiv.org/abs/1505.04597)]

#### 2015-02
- Trust Region Policy Optimization [[arXiv](https://arxiv.org/abs/1502.05477)]

#### 2014-12
- Adam: A Method for Stochastic Optimization [[arXiv](https://arxiv.org/abs/1412.6980)]

#### 2014-11
- Conditional Generative Adversarial Nets [[arXiv](https://arxiv.org/abs/1411.1784)]

#### 2014-06
- Generative Adversarial Networks [[arXiv](https://arxiv.org/abs/1406.2661)]
- Semi-Supervised Learning with Deep Generative Models [[arXiv](https://arxiv.org/abs/1406.5298)] [[Code](https://github.com/dpkingma/nips14-ssl)]

#### 2013-12
- Auto-Encoding Variational Bayes [[arXiv](https://arxiv.org/abs/1312.6114)]

#### 2012-06
- Variational Bayesian Inference with Stochastic Search [[arXiv](https://arxiv.org/abs/1206.6430)]
